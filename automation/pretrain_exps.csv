model,exp_type,scenario,pretrain_size,sft_size,exp_name,inst_data_json,torchx_cmd
pythia-1b,seq,c,11000,1000,pythia-1b_seq_train_c_11000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/,torchx run mast.py:train_seq --name pythia-1b_seq_train_c_11000 --nnodes 2 -- --steps_to_train 11000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/ --run_id pythia-1b_seq_train_c_11000
pythia-1b,seq,d,10000,1000,pythia-1b_seq_train_d_10000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/,torchx run mast.py:train_seq --name pythia-1b_seq_train_d_10000 --nnodes 2 -- --steps_to_train 10000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/ --run_id pythia-1b_seq_train_d_10000
pythia-1b,seq,c,12500,2500,pythia-1b_seq_train_c_12500,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/,torchx run mast.py:train_seq --name pythia-1b_seq_train_c_12500 --nnodes 2 -- --steps_to_train 12500 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/ --run_id pythia-1b_seq_train_c_12500
pythia-1b,seq,c,15000,5000,pythia-1b_seq_train_c_15000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/,torchx run mast.py:train_seq --name pythia-1b_seq_train_c_15000 --nnodes 2 -- --steps_to_train 15000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/ --run_id pythia-1b_seq_train_c_15000
pythia-1b,seq,c,110000,10000,pythia-1b_seq_train_c_110000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/,torchx run mast.py:train_seq --name pythia-1b_seq_train_c_110000 --nnodes 2 -- --steps_to_train 110000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/ --run_id pythia-1b_seq_train_c_110000
pythia-1b,seq,d,100000,10000,pythia-1b_seq_train_d_100000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/,torchx run mast.py:train_seq --name pythia-1b_seq_train_d_100000 --nnodes 2 -- --steps_to_train 100000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/ --run_id pythia-1b_seq_train_d_100000
pythia-1b,seq,c,125000,25000,pythia-1b_seq_train_c_125000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/,torchx run mast.py:train_seq --name pythia-1b_seq_train_c_125000 --nnodes 2 -- --steps_to_train 125000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/ --run_id pythia-1b_seq_train_c_125000
pythia-1b,seq,c,150000,50000,pythia-1b_seq_train_c_150000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/,torchx run mast.py:train_seq --name pythia-1b_seq_train_c_150000 --nnodes 2 -- --steps_to_train 150000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/ --run_id pythia-1b_seq_train_c_150000
pythia-1b,mixed,a,9000,1000,pythia-1b_mixed_train_a_9000_sft0_1,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/,torchx run mast.py:train_mixed --name pythia-1b_mixed_train_a_9000_sft0_1 --nnodes 2 -- --steps_to_train 9000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/ --run_id pythia-1b_mixed_train_a_9000_sft0_1
pythia-1b,mixed,a,7500,2500,pythia-1b_mixed_train_a_7500_sft0_25,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/,torchx run mast.py:train_mixed --name pythia-1b_mixed_train_a_7500_sft0_25 --nnodes 2 -- --steps_to_train 7500 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/ --run_id pythia-1b_mixed_train_a_7500_sft0_25
pythia-1b,mixed,a,5000,5000,pythia-1b_mixed_train_a_5000_sft0_5,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/,torchx run mast.py:train_mixed --name pythia-1b_mixed_train_a_5000_sft0_5 --nnodes 2 -- --steps_to_train 5000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/ --run_id pythia-1b_mixed_train_a_5000_sft0_5
pythia-1b,mixed,a,90000,10000,pythia-1b_mixed_train_a_90000_sft0_1,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/,torchx run mast.py:train_mixed --name pythia-1b_mixed_train_a_90000_sft0_1 --nnodes 2 -- --steps_to_train 90000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/ --run_id pythia-1b_mixed_train_a_90000_sft0_1
pythia-1b,mixed,a,75000,25000,pythia-1b_mixed_train_a_75000_sft0_25,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/,torchx run mast.py:train_mixed --name pythia-1b_mixed_train_a_75000_sft0_25 --nnodes 2 -- --steps_to_train 75000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/ --run_id pythia-1b_mixed_train_a_75000_sft0_25
pythia-1b,mixed,a,50000,50000,pythia-1b_mixed_train_a_50000_sft0_5,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/,torchx run mast.py:train_mixed --name pythia-1b_mixed_train_a_50000_sft0_5 --nnodes 2 -- --steps_to_train 50000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/ --run_id pythia-1b_mixed_train_a_50000_sft0_5
pythia-2.8b,seq,c,11000,1000,pythia-2.8b_seq_train_c_11000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/,torchx run mast.py:train_seq --name pythia-2.8b_seq_train_c_11000 --nnodes 2 -- --steps_to_train 11000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/ --run_id pythia-2.8b_seq_train_c_11000
pythia-2.8b,seq,d,10000,1000,pythia-2.8b_seq_train_d_10000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/,torchx run mast.py:train_seq --name pythia-2.8b_seq_train_d_10000 --nnodes 2 -- --steps_to_train 10000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/ --run_id pythia-2.8b_seq_train_d_10000
pythia-2.8b,seq,c,12500,2500,pythia-2.8b_seq_train_c_12500,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/,torchx run mast.py:train_seq --name pythia-2.8b_seq_train_c_12500 --nnodes 2 -- --steps_to_train 12500 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/ --run_id pythia-2.8b_seq_train_c_12500
pythia-2.8b,seq,c,15000,5000,pythia-2.8b_seq_train_c_15000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/,torchx run mast.py:train_seq --name pythia-2.8b_seq_train_c_15000 --nnodes 2 -- --steps_to_train 15000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/ --run_id pythia-2.8b_seq_train_c_15000
pythia-2.8b,seq,c,110000,10000,pythia-2.8b_seq_train_c_110000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/,torchx run mast.py:train_seq --name pythia-2.8b_seq_train_c_110000 --nnodes 2 -- --steps_to_train 110000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/ --run_id pythia-2.8b_seq_train_c_110000
pythia-2.8b,seq,d,100000,10000,pythia-2.8b_seq_train_d_100000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/,torchx run mast.py:train_seq --name pythia-2.8b_seq_train_d_100000 --nnodes 2 -- --steps_to_train 100000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/ --run_id pythia-2.8b_seq_train_d_100000
pythia-2.8b,seq,c,125000,25000,pythia-2.8b_seq_train_c_125000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/,torchx run mast.py:train_seq --name pythia-2.8b_seq_train_c_125000 --nnodes 2 -- --steps_to_train 125000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/ --run_id pythia-2.8b_seq_train_c_125000
pythia-2.8b,seq,c,150000,50000,pythia-2.8b_seq_train_c_150000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/,torchx run mast.py:train_seq --name pythia-2.8b_seq_train_c_150000 --nnodes 2 -- --steps_to_train 150000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/ --run_id pythia-2.8b_seq_train_c_150000
pythia-2.8b,mixed,a,9000,1000,pythia-2.8b_mixed_train_a_9000_sft0_1,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/,torchx run mast.py:train_mixed --name pythia-2.8b_mixed_train_a_9000_sft0_1 --nnodes 2 -- --steps_to_train 9000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/ --run_id pythia-2.8b_mixed_train_a_9000_sft0_1
pythia-2.8b,mixed,a,7500,2500,pythia-2.8b_mixed_train_a_7500_sft0_25,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/,torchx run mast.py:train_mixed --name pythia-2.8b_mixed_train_a_7500_sft0_25 --nnodes 2 -- --steps_to_train 7500 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/ --run_id pythia-2.8b_mixed_train_a_7500_sft0_25
pythia-2.8b,mixed,a,5000,5000,pythia-2.8b_mixed_train_a_5000_sft0_5,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/,torchx run mast.py:train_mixed --name pythia-2.8b_mixed_train_a_5000_sft0_5 --nnodes 2 -- --steps_to_train 5000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/ --run_id pythia-2.8b_mixed_train_a_5000_sft0_5
pythia-2.8b,mixed,a,90000,10000,pythia-2.8b_mixed_train_a_90000_sft0_1,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/,torchx run mast.py:train_mixed --name pythia-2.8b_mixed_train_a_90000_sft0_1 --nnodes 2 -- --steps_to_train 90000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/ --run_id pythia-2.8b_mixed_train_a_90000_sft0_1
pythia-2.8b,mixed,a,75000,25000,pythia-2.8b_mixed_train_a_75000_sft0_25,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/,torchx run mast.py:train_mixed --name pythia-2.8b_mixed_train_a_75000_sft0_25 --nnodes 2 -- --steps_to_train 75000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/ --run_id pythia-2.8b_mixed_train_a_75000_sft0_25
pythia-2.8b,mixed,a,50000,50000,pythia-2.8b_mixed_train_a_50000_sft0_5,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/,torchx run mast.py:train_mixed --name pythia-2.8b_mixed_train_a_50000_sft0_5 --nnodes 2 -- --steps_to_train 50000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/ --run_id pythia-2.8b_mixed_train_a_50000_sft0_5
meta-llama/Meta-Llama-3-8B,seq,c,11000,1000,meta-llama/Meta-Llama-3-8B_seq_train_c_11000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/,torchx run mast.py:train_seq --name meta-llama/Meta-Llama-3-8B_seq_train_c_11000 --nnodes 2 -- --steps_to_train 11000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/ --run_id meta-llama/Meta-Llama-3-8B_seq_train_c_11000
meta-llama/Meta-Llama-3-8B,seq,d,10000,1000,meta-llama/Meta-Llama-3-8B_seq_train_d_10000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/,torchx run mast.py:train_seq --name meta-llama/Meta-Llama-3-8B_seq_train_d_10000 --nnodes 2 -- --steps_to_train 10000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/ --run_id meta-llama/Meta-Llama-3-8B_seq_train_d_10000
meta-llama/Meta-Llama-3-8B,seq,c,12500,2500,meta-llama/Meta-Llama-3-8B_seq_train_c_12500,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/,torchx run mast.py:train_seq --name meta-llama/Meta-Llama-3-8B_seq_train_c_12500 --nnodes 2 -- --steps_to_train 12500 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/ --run_id meta-llama/Meta-Llama-3-8B_seq_train_c_12500
meta-llama/Meta-Llama-3-8B,seq,c,15000,5000,meta-llama/Meta-Llama-3-8B_seq_train_c_15000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/,torchx run mast.py:train_seq --name meta-llama/Meta-Llama-3-8B_seq_train_c_15000 --nnodes 2 -- --steps_to_train 15000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/ --run_id meta-llama/Meta-Llama-3-8B_seq_train_c_15000
meta-llama/Meta-Llama-3-8B,seq,c,110000,10000,meta-llama/Meta-Llama-3-8B_seq_train_c_110000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/,torchx run mast.py:train_seq --name meta-llama/Meta-Llama-3-8B_seq_train_c_110000 --nnodes 2 -- --steps_to_train 110000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/ --run_id meta-llama/Meta-Llama-3-8B_seq_train_c_110000
meta-llama/Meta-Llama-3-8B,seq,d,100000,10000,meta-llama/Meta-Llama-3-8B_seq_train_d_100000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/,torchx run mast.py:train_seq --name meta-llama/Meta-Llama-3-8B_seq_train_d_100000 --nnodes 2 -- --steps_to_train 100000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/ --run_id meta-llama/Meta-Llama-3-8B_seq_train_d_100000
meta-llama/Meta-Llama-3-8B,seq,c,125000,25000,meta-llama/Meta-Llama-3-8B_seq_train_c_125000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/,torchx run mast.py:train_seq --name meta-llama/Meta-Llama-3-8B_seq_train_c_125000 --nnodes 2 -- --steps_to_train 125000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/ --run_id meta-llama/Meta-Llama-3-8B_seq_train_c_125000
meta-llama/Meta-Llama-3-8B,seq,c,150000,50000,meta-llama/Meta-Llama-3-8B_seq_train_c_150000,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/,torchx run mast.py:train_seq --name meta-llama/Meta-Llama-3-8B_seq_train_c_150000 --nnodes 2 -- --steps_to_train 150000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/ --run_id meta-llama/Meta-Llama-3-8B_seq_train_c_150000
meta-llama/Meta-Llama-3-8B,mixed,a,9000,1000,meta-llama/Meta-Llama-3-8B_mixed_train_a_9000_sft0_1,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/,torchx run mast.py:train_mixed --name meta-llama/Meta-Llama-3-8B_mixed_train_a_9000_sft0_1 --nnodes 2 -- --steps_to_train 9000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/1000/ --run_id meta-llama/Meta-Llama-3-8B_mixed_train_a_9000_sft0_1
meta-llama/Meta-Llama-3-8B,mixed,a,7500,2500,meta-llama/Meta-Llama-3-8B_mixed_train_a_7500_sft0_25,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/,torchx run mast.py:train_mixed --name meta-llama/Meta-Llama-3-8B_mixed_train_a_7500_sft0_25 --nnodes 2 -- --steps_to_train 7500 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/2500/ --run_id meta-llama/Meta-Llama-3-8B_mixed_train_a_7500_sft0_25
meta-llama/Meta-Llama-3-8B,mixed,a,5000,5000,meta-llama/Meta-Llama-3-8B_mixed_train_a_5000_sft0_5,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/,torchx run mast.py:train_mixed --name meta-llama/Meta-Llama-3-8B_mixed_train_a_5000_sft0_5 --nnodes 2 -- --steps_to_train 5000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/5000/ --run_id meta-llama/Meta-Llama-3-8B_mixed_train_a_5000_sft0_5
meta-llama/Meta-Llama-3-8B,mixed,a,90000,10000,meta-llama/Meta-Llama-3-8B_mixed_train_a_90000_sft0_1,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/,torchx run mast.py:train_mixed --name meta-llama/Meta-Llama-3-8B_mixed_train_a_90000_sft0_1 --nnodes 2 -- --steps_to_train 90000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/10000/ --run_id meta-llama/Meta-Llama-3-8B_mixed_train_a_90000_sft0_1
meta-llama/Meta-Llama-3-8B,mixed,a,75000,25000,meta-llama/Meta-Llama-3-8B_mixed_train_a_75000_sft0_25,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/,torchx run mast.py:train_mixed --name meta-llama/Meta-Llama-3-8B_mixed_train_a_75000_sft0_25 --nnodes 2 -- --steps_to_train 75000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/25000/ --run_id meta-llama/Meta-Llama-3-8B_mixed_train_a_75000_sft0_25
meta-llama/Meta-Llama-3-8B,mixed,a,50000,50000,meta-llama/Meta-Llama-3-8B_mixed_train_a_50000_sft0_5,/mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/,torchx run mast.py:train_mixed --name meta-llama/Meta-Llama-3-8B_mixed_train_a_50000_sft0_5 --nnodes 2 -- --steps_to_train 50000 --instruction_data_json /mnt/mffuse/all_in_one_pretraining/datasets/sft/concat/50000/ --run_id meta-llama/Meta-Llama-3-8B_mixed_train_a_50000_sft0_5
